{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以3层神经网络为对象，输入层（第0层）有2个神经元，隐藏层（第1层）有3个神经元，隐藏层（第2层）有2个神经元，输出层（第3层）有2个神经元。\n",
    "实现从输入到输出的前向处理。\n",
    "\n",
    "    第0层输入神经元：x1,x2\n",
    "    第1层隐藏层神经元：a1,a2,a3\n",
    "    第2层隐藏层神经元：b1,b2\n",
    "    第3层输出层神经元：y1，y2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "从输入层到第1层的信号传递\n",
    "a1=x1*w11+x2*w21+b1   #偏置权重b中的元素数量取决于后一层神经元的数量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 3)\n",
      "(2,)\n",
      "(3,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "X=np.array([1.0,0.5])\n",
    "W1=np.array([[0.1,0.3,0.5],[0.2,0.4,0.6]])\n",
    "B1=np.array([0.1,0.2,0.3])\n",
    "print(W1.shape)\n",
    "print(X.shape)\n",
    "print(B1.shape)\n",
    "A1=np.dot(X,W1)+B1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以上计算出了隐藏层第1层的加权和（加权信号和偏置的总和）用A表示，加下来计算其被激活函数转换后，用Z表示"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.3 0.7 1.1]\n",
      "[0.57444252 0.66818777 0.75026011]\n"
     ]
    }
   ],
   "source": [
    "def sigmoid(x):\n",
    "    return 1/(1+np.exp(-x))\n",
    "\n",
    "Z1=sigmoid(A1)\n",
    "print(A1)\n",
    "print(Z1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "第一层到第二层的信号传递：\n",
    "第一层的输出Z1 变成第二层的输入"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3,)\n",
      "(3, 2)\n",
      "(2,)\n",
      "[0.51615984 1.21402696]\n",
      "[0.62624937 0.7710107 ]\n"
     ]
    }
   ],
   "source": [
    "W2=np.array([[0.1,0.4],[0.2,0.5],[0.3,0.6]])\n",
    "B2=np.array([0.1,0.2])\n",
    "print(Z1.shape)\n",
    "print(W2.shape)\n",
    "print(B2.shape)\n",
    "A2=np.dot(Z1,W2)+B2\n",
    "Z2=sigmoid(A2)\n",
    "print(A2)\n",
    "print(Z2)   \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "最后是第二层到输出层的信号传递，最后的激活函数和之前的隐藏层有所不同。\n",
    "#输出层的激活函数用恒等函数 ，恒等函数会将输入按原样输出\n",
    "输出层所用的激活函数，要根据求解问题的性质决定。一般回归问题用恒等函数，二元分类问题用sigmoid函数，多元分类问题用softmax函数\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.31682708 0.69627909]\n"
     ]
    }
   ],
   "source": [
    "def identity_function(x):   #恒等函数\n",
    "    return x    \n",
    "\n",
    "W3=np.array([[0.1,0.3],[0.2,0.4]])\n",
    "B3=np.array([0.1,0.2])\n",
    "\n",
    "A3=np.dot(Z2,W3)+B3\n",
    "Y=identity_function(A3)\n",
    "print(Y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.31682708 0.69627909]\n"
     ]
    }
   ],
   "source": [
    "#全部3层网络的实现代码\n",
    "def init_network():\n",
    "    network={}\n",
    "    network['W1']=np.array([[0.1,0.3,0.5],[0.2,0.4,0.6]])\n",
    "    network['b1']=np.array([0.1,0.2,0.3])\n",
    "    network['W2']=np.array([[0.1,0.4],[0.2,0.5],[0.3,0.6]])\n",
    "    network['b2']=np.array([0.1,0.2])\n",
    "    network['W3']=np.array([[0.1,0.3],[0.2,0.4]])\n",
    "    network['b3']=np.array([0.1,0.2])\n",
    "    return network\n",
    "\n",
    "def forward(network,x):\n",
    "    W1,W2,W3=network['W1'],network['W2'],network['W3']\n",
    "    b1,b2,b3=network['b1'],network['b2'],network['b3']\n",
    "    a1=np.dot(x,W1)+b1\n",
    "    z1=sigmoid(a1)\n",
    "    a2=np.dot(z1,W2)+b2\n",
    "    z2=sigmoid(a2)\n",
    "    a3=np.dot(z2,W3)+b3\n",
    "    y=identity_function(a3)\n",
    "    return y\n",
    "network=init_network()\n",
    "x=np.array([1.0,0.5])     #输入层\n",
    "y=forward(network,x)      #输出层\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "softmax函数：\n",
    "$$\n",
    "y_k = \\frac{exp(a_k)}{\\sum_{i=1}^nexp(a_i)}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "输出层的设计：神经网络可以用在分类问题和回归问题上，需要根据情况改变输出层的激活函数\n",
    "     \n",
    "     分类问题：输出层的神经元数为分类数，激活函数为softmax函数。（比如区分图像是男性还是女性）\n",
    "     回归问题：输出层的神经元数为1，激活函数为恒等函数。（比如根据一个人的图像预测这个人的体重，类似“54.5kg”这样的预测）\n",
    "\n",
    "    输出层的激活函数：\n",
    "        回归问题：恒等函数，对于输入信息，不加任何改动的直接输出\n",
    "        分类问题：softmax函数  \n",
    "        （softmax函数的输出是0.0到1.0之间的实数，并且所有输出值的和为1。）\n",
    "        神经网络的输出是0.7的话，这表示“70%的概率是这个图像是男性，30%的概率是这个图像是女性”。\n",
    "        softmax函数式：\n",
    "            yk = exp(ak) / Σexp(ai)\n",
    "            exp(x)表示e的x次方，假设输出层共有n个输出，计算第k个神经元的输出为yk,\n",
    "            那么softmax函数的表达式为：\n",
    "            y1 = exp(a1) / (exp(a1) + exp(a2) + ... + exp(an))\n",
    "            y2 = exp(a2) / (exp(a1) + exp(a2) + ... + exp(an))\n",
    "            ...\n",
    "            yn = exp(an) / (exp(a1) + exp(a2) + ... + exp(an))\n",
    "            其中，yk是第k个输出，ak是神经网络的第k个输出，i是和号的下标，表示对所有的输出求和。\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.34985881 18.17414537 54.59815003]\n",
      "74.1221542101633\n",
      "[0.01821127 0.24519181 0.73659691]\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "a=np.array([0.3,2.9,4.0])\n",
    "exp_a=np.exp(a)\n",
    "print(exp_a)\n",
    "sum_exp_a=np.sum(exp_a)\n",
    "print(sum_exp_a)\n",
    "y=exp_a/sum_exp_a\n",
    "print(y)\n",
    "print(np.sum(y))    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#定义softmax函数\n",
    "def softmax(a):\n",
    "    exp_a=np.exp(a)\n",
    "    sum_exp_a=np.sum(exp_a)\n",
    "    y=exp_a/sum_exp_a\n",
    "    return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "实现softmax函数时的注意事项：\n",
    "计算时需要注意溢出问题，softmax函数的实现中要实现函数的指数运算，此时指数函数的值很容易变得很大，即输入值过大或过小导致指数函数的计算结果超出表示范围。\n",
    "为了防止溢出，一般会在计算指数函数之前，先将输入值减去最大值，这样最大值就变成了0，其他值就都变成了负数。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "比如e的10次方会超过20000，e的100次方会变成后面有40多个0的超大值，e的1000次方会返回一个表示无穷大的inf，计算机在处理数时，数值必须在4字节或者8字节的有限宽度内。这意味着数存在有效位数，也就是说可以表示数值的范围是有限的。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9.99954600e-01, 4.53978686e-05, 2.06106005e-09])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "a=np.array([1010,1000,990])\n",
    "#np.exp(a)/np.sum(np.exp(a))   #[nan,nan,nan]\n",
    "c=np.max(a)\n",
    "a-c\n",
    "np.exp(a-c)/np.sum(np.exp(a-c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(a):\n",
    "    c=np.max(a)\n",
    "    exp_a=np.exp(a-c)\n",
    "    sum_exp_a=np.sum(exp_a)\n",
    "    y=exp_a/sum_exp_a\n",
    "    return y\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "softmax 函数的特征：\n",
    "1、softmax 函数的输出是0到1之间的实数。\n",
    "2、softmax 函数的输出值之和为1。\n",
    "3、softmax 函数的输出值可以解释为概率。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "输出层神经元的数量：\n",
    "输出层神经元的数量需要根据待解决的问题来确定。\n",
    "如果是分类问题，输出层神经元的数量需要等于分类的类别数。\n",
    "如果是回归问题，输出层神经元的数量需要等于待预测的数值的数量。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
