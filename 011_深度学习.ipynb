{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b746ad71",
   "metadata": {},
   "source": [
    "深度学习是加深了层的深度神经网络"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e8fbac5",
   "metadata": {},
   "source": [
    "#### 加深网络\n",
    "\n",
    "向更深的网络出发，这个网络的层比之前实现的网络都更深。这里使用的卷积层全都是3×3的小型滤波器，特点是随着层的加深，通道数变大（卷积层的通道数从前面的层开始按顺序以16、16、32、32、64、64的方式增加）。此外，如图8-1所示，插入了池化层，以逐渐减小中间数据的空间大小；并且，后面的全连接层中使用了Dropout层。\n",
    "\n",
    "这个网络使用He初始值作为权重的初始值，使用Adam更新权重参数。把上述内容总结起来，这个网络有如下特点\n",
    "- 基于3x3的小型滤波器的卷积层\n",
    "- 激活函数是ReLU\n",
    "- 全连接层的后面使用Dropout层\n",
    "- 基于Adam 的最优化\n",
    "- 权重初始值是He初始值\n",
    "\n",
    "这个网络的识别精度为99.38%\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a383efb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# coding: utf-8\n",
    "import sys, os\n",
    "sys.path.append(os.pardir)  # 为了导入父目录的文件而进行的设定\n",
    "import pickle\n",
    "import numpy as np\n",
    "from collections import OrderedDict\n",
    "from common.layers import *\n",
    "\n",
    "\n",
    "class DeepConvNet:\n",
    "    \"\"\"识别率为99%以上的高精度的ConvNet\n",
    "\n",
    "    网络结构如下所示\n",
    "        conv - relu - conv- relu - pool -\n",
    "        conv - relu - conv- relu - pool -\n",
    "        conv - relu - conv- relu - pool -\n",
    "        affine - relu - dropout - affine - dropout - softmax\n",
    "    \"\"\"\n",
    "    def __init__(self, input_dim=(1, 28, 28),\n",
    "                 conv_param_1 = {'filter_num':16, 'filter_size':3, 'pad':1, 'stride':1},\n",
    "                 conv_param_2 = {'filter_num':16, 'filter_size':3, 'pad':1, 'stride':1},\n",
    "                 conv_param_3 = {'filter_num':32, 'filter_size':3, 'pad':1, 'stride':1},\n",
    "                 conv_param_4 = {'filter_num':32, 'filter_size':3, 'pad':2, 'stride':1},\n",
    "                 conv_param_5 = {'filter_num':64, 'filter_size':3, 'pad':1, 'stride':1},\n",
    "                 conv_param_6 = {'filter_num':64, 'filter_size':3, 'pad':1, 'stride':1},\n",
    "                 hidden_size=50, output_size=10):\n",
    "        # 初始化权重===========\n",
    "        # 各层的神经元平均与前一层的几个神经元有连接（TODO:自动计算）\n",
    "        pre_node_nums = np.array([1*3*3, 16*3*3, 16*3*3, 32*3*3, 32*3*3, 64*3*3, 64*4*4, hidden_size])\n",
    "        wight_init_scales = np.sqrt(2.0 / pre_node_nums)  # 使用ReLU的情况下推荐的初始值\n",
    "        \n",
    "        self.params = {}\n",
    "        pre_channel_num = input_dim[0]\n",
    "        for idx, conv_param in enumerate([conv_param_1, conv_param_2, conv_param_3, conv_param_4, conv_param_5, conv_param_6]):\n",
    "            self.params['W' + str(idx+1)] = wight_init_scales[idx] * np.random.randn(conv_param['filter_num'], pre_channel_num, conv_param['filter_size'], conv_param['filter_size'])\n",
    "            self.params['b' + str(idx+1)] = np.zeros(conv_param['filter_num'])\n",
    "            pre_channel_num = conv_param['filter_num']\n",
    "        self.params['W7'] = wight_init_scales[6] * np.random.randn(64*4*4, hidden_size)\n",
    "        self.params['b7'] = np.zeros(hidden_size)\n",
    "        self.params['W8'] = wight_init_scales[7] * np.random.randn(hidden_size, output_size)\n",
    "        self.params['b8'] = np.zeros(output_size)\n",
    "\n",
    "        # 生成层===========\n",
    "        self.layers = []\n",
    "        self.layers.append(Convolution(self.params['W1'], self.params['b1'], \n",
    "                           conv_param_1['stride'], conv_param_1['pad']))\n",
    "        self.layers.append(Relu())\n",
    "        self.layers.append(Convolution(self.params['W2'], self.params['b2'], \n",
    "                           conv_param_2['stride'], conv_param_2['pad']))\n",
    "        self.layers.append(Relu())\n",
    "        self.layers.append(Pooling(pool_h=2, pool_w=2, stride=2))\n",
    "        self.layers.append(Convolution(self.params['W3'], self.params['b3'], \n",
    "                           conv_param_3['stride'], conv_param_3['pad']))\n",
    "        self.layers.append(Relu())\n",
    "        self.layers.append(Convolution(self.params['W4'], self.params['b4'],\n",
    "                           conv_param_4['stride'], conv_param_4['pad']))\n",
    "        self.layers.append(Relu())\n",
    "        self.layers.append(Pooling(pool_h=2, pool_w=2, stride=2))\n",
    "        self.layers.append(Convolution(self.params['W5'], self.params['b5'],\n",
    "                           conv_param_5['stride'], conv_param_5['pad']))\n",
    "        self.layers.append(Relu())\n",
    "        self.layers.append(Convolution(self.params['W6'], self.params['b6'],\n",
    "                           conv_param_6['stride'], conv_param_6['pad']))\n",
    "        self.layers.append(Relu())\n",
    "        self.layers.append(Pooling(pool_h=2, pool_w=2, stride=2))\n",
    "        self.layers.append(Affine(self.params['W7'], self.params['b7']))\n",
    "        self.layers.append(Relu())\n",
    "        self.layers.append(Dropout(0.5))\n",
    "        self.layers.append(Affine(self.params['W8'], self.params['b8']))\n",
    "        self.layers.append(Dropout(0.5))\n",
    "        \n",
    "        self.last_layer = SoftmaxWithLoss()\n",
    "\n",
    "    def predict(self, x, train_flg=False):\n",
    "        for layer in self.layers:\n",
    "            if isinstance(layer, Dropout):\n",
    "                x = layer.forward(x, train_flg)\n",
    "            else:\n",
    "                x = layer.forward(x)\n",
    "        return x\n",
    "\n",
    "    def loss(self, x, t):\n",
    "        y = self.predict(x, train_flg=True)\n",
    "        return self.last_layer.forward(y, t)\n",
    "\n",
    "    def accuracy(self, x, t, batch_size=100):\n",
    "        if t.ndim != 1 : t = np.argmax(t, axis=1)\n",
    "\n",
    "        acc = 0.0\n",
    "\n",
    "        for i in range(int(x.shape[0] / batch_size)):\n",
    "            tx = x[i*batch_size:(i+1)*batch_size]\n",
    "            tt = t[i*batch_size:(i+1)*batch_size]\n",
    "            y = self.predict(tx, train_flg=False)\n",
    "            y = np.argmax(y, axis=1)\n",
    "            acc += np.sum(y == tt)\n",
    "\n",
    "        return acc / x.shape[0]\n",
    "\n",
    "    def gradient(self, x, t):\n",
    "        # forward\n",
    "        self.loss(x, t)\n",
    "\n",
    "        # backward\n",
    "        dout = 1\n",
    "        dout = self.last_layer.backward(dout)\n",
    "\n",
    "        tmp_layers = self.layers.copy()\n",
    "        tmp_layers.reverse()\n",
    "        for layer in tmp_layers:\n",
    "            dout = layer.backward(dout)\n",
    "\n",
    "        # 设定\n",
    "        grads = {}\n",
    "        for i, layer_idx in enumerate((0, 2, 5, 7, 10, 12, 15, 18)):\n",
    "            grads['W' + str(i+1)] = self.layers[layer_idx].dW\n",
    "            grads['b' + str(i+1)] = self.layers[layer_idx].db\n",
    "\n",
    "        return grads\n",
    "\n",
    "    def save_params(self, file_name=\"params.pkl\"):\n",
    "        params = {}\n",
    "        for key, val in self.params.items():\n",
    "            params[key] = val\n",
    "        with open(file_name, 'wb') as f:\n",
    "            pickle.dump(params, f)\n",
    "\n",
    "    def load_params(self, file_name=\"params.pkl\"):\n",
    "        with open(file_name, 'rb') as f:\n",
    "            params = pickle.load(f)\n",
    "        for key, val in params.items():\n",
    "            self.params[key] = val\n",
    "\n",
    "        for i, layer_idx in enumerate((0, 2, 5, 7, 10, 12, 15, 18)):\n",
    "            self.layers[layer_idx].W = self.params['W' + str(i+1)]\n",
    "            self.layers[layer_idx].b = self.params['b' + str(i+1)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fc7e31a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# coding: utf-8\n",
    "import sys, os\n",
    "sys.path.append(os.pardir)  # 为了导入父目录而进行的设定\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from digit_recognition.mnist import load_mnist\n",
    "from common.trainer import Trainer\n",
    "\n",
    "(x_train, t_train), (x_test, t_test) = load_mnist(flatten=False)\n",
    "\n",
    "network = DeepConvNet()  \n",
    "trainer = Trainer(network, x_train, t_train, x_test, t_test,\n",
    "                  epochs=20, mini_batch_size=100,\n",
    "                  optimizer='Adam', optimizer_param={'lr':0.001},\n",
    "                  evaluate_sample_num_per_epoch=1000)\n",
    "trainer.train()\n",
    "\n",
    "# 保存参数\n",
    "network.save_params(\"deep_convnet_params.pkl\")\n",
    "print(\"Saved Network Parameters!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cb15bd6",
   "metadata": {},
   "source": [
    "对于MNIST数据集，层不用特别深就获得了（目前）最高的识别精度。一般认为，这是因为对于手写数字识别这样一个比较简单的任务，没有必要将网络的表现力提高到那么高的程度。因此，可以说加深层的好处并不大。而之后要介绍的大规模的一般物体识别的情况，因为问题复杂，所以加深层对提高识别精度大有裨益。可以发现进一步提高识别精度的技术和线索。比如，集成学习、学习率衰减、Data Augmentation（数据扩充）等都有助于提高识别精度。尤其是Data Augmentation，虽然方法很简单，但在提高识别精度上效果显著。\n",
    "\n",
    "Data Augmentation基于算法“人为地”扩充输入图像（训练图像）。具体地说，如图8-4所示，对于输入图像，通过施加旋转、垂直或水平方向上的移动等微小变化，增加图像的数量。这在数据集的图像数量有限时尤其有效。Data Augmentation还可以通过其他各种方法扩充图像，比如裁剪图像的“crop处理”、将图像左右翻转的“fip处理”A等。对于一般的图像，施加亮度等外观上的变化、放大缩小等尺度上的变化也是有效的。不管怎样，通过Data Augmentation巧妙地增加训练图像，就可以提高深度学习的识别精度。虽然这个看上去只是一个简单的技巧，不过经常会有很好的效果。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15e641b1",
   "metadata": {},
   "source": [
    "加深层的动机\n",
    "\n",
    "    加深层的好处：\n",
    "    1、增加了网络的表示能力，通过加深网络，可以拟合更加复杂的函数。\n",
    "    2、参数数量的减少：\n",
    "        卷积神经网络中，参数的数量和输入数据的大小、卷积核的大小、通道数以及卷积核的数量都有关系。\n",
    "        随着网络的加深，参数的数量会增加，这对于训练大型数据集是一个挑战。\n",
    "        通过增加网络的深度，参数的数量会减少，这使得模型的训练更加高效。\n",
    "    3、使学习更加高效\n",
    "        与没有加深层的网络相比，通过加深层，可以减少学习数据，从而高效地进行学习。具体地说，在前面的卷积层中，神经元会对边缘等简单的形状有响应，随着层的加深，开始对纹理、物体部件等更加复杂的东西有响应。\n",
    "    4、通过加深网络，可以分层次的分解需要学习的问题，因此各层需要学习的问题就变成了更简单的问题，因为提取了边缘的层的下一层能够使用边缘的信息，所以应该能够高效地学习更加高级的模式。也就是说，通过加深层，可以将各层要学习的问题分解成容易解决的简单问题，从而可以进行高效的学习。\n",
    "    5、平移不变性：\n",
    "        卷积神经网络中的卷积层能够提取输入数据中的局部特征，这些局部特征对于平移具有不变性。\n",
    "        也就是说，无论物体在图像中的位置如何变化，卷积层都能够提取到相同的特征。\n",
    "        通过增加网络的深度，平移不变性得到了更好的利用\n",
    "    6、通过加深层，可以分层次的传递信息，\n",
    "    7、更深层次的网络可以更好地提取特征：\n",
    "        随着网络的加深，卷积层能够提取到更加抽象和高级的特征。\n",
    "        这些特征对于分类任务更加重要，因为它们能够提供更丰富的信息。\n",
    "        更深层次的网络可以更好地利用这些特征，提高分类的准确性。\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5efbae4e",
   "metadata": {},
   "source": [
    "叠加小型滤波器来加深网络的好处是可以减少参数的数量，扩大感受野（receptive field，给神经元施加变化的某个局部空间区域）。并且，通过叠加层，将ReLU等激活函数夹在卷积层的中间，进一步提高了网络的表现力。这是因为向网络添加了基于激活函数的“非线性”表现力，通过非线性函数的叠加，可以表现更加复杂的东西。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80db7d89",
   "metadata": {},
   "source": [
    "深度学习小历史\n",
    "\n",
    "    ImageNet：拥有超过100万张图像的数据集它包含了各种各样的图像，并且每张图像都被关联了标签（类别名）。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3acc6154",
   "metadata": {},
   "source": [
    "VGG:\n",
    "\n",
    "    VGG是由卷积层和池化层构成的基础的CNN。它的特点在于将有权重的层（卷积层或者全连接层）叠加至16层（或者19层），具备了深度（根据层的深度，有时也称为“VGG16”或“VGG19”）。VGG中需要注意的地方是，基于3×3的小型滤波器的卷积层的运算是连续进行的。重复进行“卷积层重叠2次到4次，再通过池化层将大小减半”的处理，最后经由全连接层输出结果。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28b0dcff",
   "metadata": {},
   "source": [
    "GoogLeNet:\n",
    "\n",
    "    GoogLeNet的特征是，网络不仅在纵向上有深度，在横向上也有深度（广度）。GoogLeNet在横向上有“宽度”，这称为“Inception结构”Inception结构使用了多个大小不同的滤波器（和池化），最后再合并它们的结果。GoogLeNet的特征就是将这个Inception结构用作一个构件（构成元素）。此外，在GoogLeNet中，很多地方都使用了大小为1×1的滤波器的卷积层。这个1×1的卷积运算通过在通道方向上减小大小，有助于减少参数和实现高速化处理"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bd8b960",
   "metadata": {},
   "source": [
    "ResNet：\n",
    "\n",
    "    ResNet[24]是微软团队开发的网络。它的特征在于具有比以前的网络更深的结构。已经知道加深层对于提升性能很重要。但是，在深度学习中，过度加深层的话，很多情况下学习将不能顺利进行，导致最终性能不佳。ResNet中，为了解决这类问题，导入了“快捷结构”（也称为“捷径”或“小路”）。导入这个快捷结构后，就可以随着层的加深而不断提高性能了（当然，层的加深也是有限度的）。快捷结构横跨（跳过）了输入数据的卷积层，将输入x合计到输出。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c61c9f69",
   "metadata": {},
   "source": [
    "因为快捷结构只是原封不动地传递输入数据，所以反向传播时会将来自上游的梯度原封不动地传向下游。这里的重点是不对来自上游的梯度进行任何处理，将其原封不动地传向下游。因此，基于快捷结构，不用担心梯度会变小（或变大），能够向前一层传递“有意义的梯度”。通过这个快捷结构，之前因为加深层而导致的梯度变小的梯度消失问题就有望得到缓解。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfd98d4d",
   "metadata": {},
   "source": [
    "实践中经常会灵活应用使用ImageNet这个巨大的数据集学习到的权重数据，这称为迁移学习，将学习完的权重（的一部分）复制到其他神经网络，进行再学习（finetuning）。比如，准备一个和VGG相同结构的网络，把学习完的权重作为初始值，以新数据集为对象，进行再学习。迁移学习在手头数据集较少时非常有效。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c818b95",
   "metadata": {},
   "source": [
    "#### 深度学习的高速化\n",
    "\n",
    "随着大数据和网络的大规模化，深度学习需要进行大量的运算。虽然到目前为止，我们都是使用CPU进行计算的，但现实是只用CPU来应对深度学习无法令人放心。实际上，环视一下周围，大多数深度学习的框架都支持GPU（Graphics Processing Unit），可以高速地处理大量的运算。另外，最近的框架也开始支持多个GPU或多台机器上的分布式学习。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b20baa2",
   "metadata": {},
   "source": [
    "需要努力解决的问题：\n",
    "\n",
    "1、  过拟合问题\n",
    "2、  学习时间问题\n",
    "\n",
    "卷积层中进行的运算可以追溯至乘积累加运算。因此，深度学习的高速化的主要课题就变成了如何高速、高效地进行大量的乘积累加运算。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0340f62f",
   "metadata": {},
   "source": [
    "基于GPU 的高速化\n",
    "\n",
    "    GPU原本是作为图像专用的显卡使用的，但最近不仅用于图像处理，也用于通用的数值计算。由于GPU可以高速地进行并行数值计算，因此GPU计算的目标就是将这种压倒性的计算能力用于各种用途。所谓GPU计算，是指基于GPU进行通用的数值计算的操作。深度学习中需要进行大量的乘积累加运算（或者大型矩阵的乘积运算）。这种大量的并行运算正是GPU所擅长的（反过来说，CPU比较擅长连续的、复杂的计算）。因此，与使用单个CPU相比，使用GPU进行深度学习的运算可以达到惊人的高速化。下面我们就来看一下基于GPU可以实现多大程度的高速化。通过使用cuDNN这个最优化的库，可以进一步实现高速化。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3de320e",
   "metadata": {},
   "source": [
    "通过im2col可以将卷积层进行的运算转换为大型矩阵的乘积。这个im2col方式的实现对GPU来说是非常方便的实现方式。这是因为，相比按小规模的单位进行计算，GPU更擅长计算大规模的汇总好的数据。也就是说，通过基于im2col以大型矩阵的乘积的方式汇总计算，更容易发挥出GPU的能力。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "026f6d85",
   "metadata": {},
   "source": [
    "分布式学习\n",
    "\n",
    "    虽然通过GPU可以实现深度学习运算的高速化，但即便如此，当网络较深时，学习还是需要几天到几周的时间。并且，前面也说过，深度学习伴随着很多试错。为了创建良好的网络，需要反复进行各种尝试，这样一来就必然会产生尽可能地缩短一次学习所需的时间的要求。于是，将深度学习的学习过程扩展开来的想法（也就是分布式学习）就变得重要起来。为了进一步提高深度学习所需的计算的速度，可以考虑在多个GPU或者多台机器上进行分布式计算。现在的深度学习框架中，出现了好几个支持多GPU或者多机器的分布式学习的框架。其中，Google的TensorFlow、微软的CNTK（Computational Network Toolki）在开发过程中高度重视分布式学习。以大型数据中心的低延迟·高吞吐网络作为支撑，基于这些框架的分布式学习呈现出惊人的效果。\n",
    "\n",
    "    随着GPU个数的增加，学习速度也在提高。实际上，与使用1个GPU时相比，使用100个GPU（设置在多台机器上，共100个）似乎可以实现56倍的高速化！这意味着之前花费7天的学习只要3个小时就能完成，充分说明了分布式学习惊人的效果。\n",
    "\n",
    "    关于分布式学习，“如何进行分布式计算”是一个非常难的课题。它包含了机器间的通信、数据的同步等多个无法轻易解决的问题。可以将这些难题都交给TensorFlow等优秀的框架。这里，我们不讨论分布式学习的细节。关于分布式学习的技术性内容，请参考TensorFlow的技术论文（白皮书）等。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2590d686",
   "metadata": {},
   "source": [
    "运算精度的位数缩减\n",
    "\n",
    "    在深度学习的高速化中，除了计算量之外，内存容量、总线带宽等也有可能成为瓶颈。关于内存容量，需要考虑将大量的权重参数或中间数据放在内存中。关于总线带宽，当流经GPU（或者CPU）总线的数据超过某个限制时，就会成为瓶颈。考虑到这些情况，我们希望尽可能减少流经网络的数据的位数。计算机中为了表示实数，主要使用64位或者32位的浮点数。通过使用较多的位来表示数字，虽然数值计算时的误差造成的影响变小了，但计算的处理成本、内存使用量却相应地增加了，还给总线带宽带来了负荷。关于数值精度（用几位数据表示数值），我们已经知道深度学习并不那么需要数值精度的位数。这是神经网络的一个重要性质。这个性质是基于神经网络的健壮性而产生的。这里所说的健壮性是指，比如，即便输入图像附有一些小的噪声，输出结果也仍然保持不变。可以认为，正是因为有了这个健壮性，流经网络的数据即便有所“劣化”，对输出结果的影响也较小。\n",
    "    计算机中表示小数时，有32位的单精度浮点数和64位的双精度浮点数等格式。根据以往的实验结果，在深度学习中，即便是16位的半精度浮点数（half foat），也可以顺利地进行学习[30]。实际上，NVIDIA的下一代GPU 框架Pascal也支持半精度浮点数的运算，由此可以认为今后半精度浮点数将被作为标准使用。以往的深度学习的实现中并没有注意数值的精度，不过Python中一般使用64位的浮点数。NumPy中提供了16位的半精度浮点数类型（不过，只有16位类型的存储，运算本身不用16位进行），即便使用NumPy的半精度浮点数，识别精度也不会下降。相关的论证也很简单，有兴趣的读者请参考ch08/half_float_network.py。\n",
    "    关于深度学习的位数缩减，到目前为止已有若干研究。最近有人提出了用1位来表示权重和中间数据的Binarized Neural Networks方法[31]。为了实现深度学习的高速化，位数缩减是今后必须关注的一个课题，特别是在面向嵌入式应用程序中使用深度学习时，位数缩减非常重要。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1c10456",
   "metadata": {},
   "source": [
    "#### 深度学习的应用案例\n",
    "\n",
    "    1、物体检测    物体检测是从图像中确定物体的位置，并进行分类的问题。\n",
    "    \n",
    "    2、图像分割    图像分割是指在像素水平上对图像进行分类。\n",
    "    \n",
    "    3、图像标题生成    一个基于深度学习生成图像标题的代表性方法是被称为NIC（Neural Image Caption）的模型NIC基于CNN从图像中提取特征，并将这个特征传给RNN，RNN以CNN提取出的特征为初始值，递归地生成文本，将组合图像和自然语言等多种信息进行的处理称为多模态处理\n",
    "    \n",
    "    4、图像生成\n",
    "\n",
    "    5、强化学习\n",
    "\n",
    "    6、生成对抗网络\n",
    "\n",
    "    7、自动驾驶\n",
    "\n",
    "    8、自然语言处理\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
